{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=documents,\n",
    "    metadatas=metadatas,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"my_collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CHUNKING LOGIC\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import csv\n",
    "\n",
    "with open('league_lore.csv', 'r', encoding = 'utf8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    championdata = [row for row in csv_reader]\n",
    "    \n",
    "chunk_size = 300\n",
    "chunk_overlap = 20\n",
    "#chunks_result = chunk_section({\"text\": csv_reader, \"source\": \"your_source\"}, chunk_size, chunk_overlap)\n",
    "\n",
    "# def chunk_section(section, chunk_size, chunk_overlap):\n",
    "#     text_splitter = RecursiveCharacterTextSplitter(\n",
    "#         separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "#         chunk_size=chunk_size,\n",
    "#         chunk_overlap=chunk_overlap,\n",
    "#         length_function=len)\n",
    "    \n",
    "#     #repeat this function for each {key:value} in list of dictionaries (loop through list of dictionaries)\n",
    "#     #at each iteration, append the new lore + metadata to the lists\n",
    "#     chunks = text_splitter.create_documents(\n",
    "#         #Find a way to retrieve the lore and metadata columns from the csv. sample_section is a dictionary. The code below is creating a list that contains the value associated with the key in dictionary sample_section\n",
    "#         texts=[championdata[\"Lore\"]], \n",
    "#         metadatas=[{\"Champion\": championdata[\"Champion\"], \"Region\": championdata[\"Region\"], \"Link\": championdata[\"Link\"]}])\n",
    "\n",
    "#     return [{\"Lore\": chunk.page_content, \"Champion\": chunk.metadata[\"Champion\"], \"Region\": chunk.metadata[\"Region\"], \"Link\": chunk.metadata[\"Link\"]} for chunk in chunks]\n",
    "\n",
    "def chunk_section(championdata, chunk_size, chunk_overlap):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len\n",
    "    )\n",
    "    \n",
    "    chunks_list = []\n",
    "    for champion_entry in championdata:\n",
    "        chunks = text_splitter.create_documents(\n",
    "            texts=[champion_entry[\"Lore\"]],\n",
    "            metadatas=[{\"Link\": champion_entry[\"Link\"], \"Champion\": champion_entry[\"Champion\"], \"Region\": champion_entry[\"Region\"]}]\n",
    "        )\n",
    "        chunks_list.extend([{\"Link\": champion_entry[\"Link\"], \"Lore\": chunk.page_content, \"Champion\": chunk.metadata[\"Champion\"], \"Region\": chunk.metadata[\"Region\"]} for chunk in chunks])\n",
    "    \n",
    "    return chunks_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCALE CHUNKING\n",
    "from functools import partial\n",
    "\n",
    "chunks_cd = championdata.flat_map(partial(chunk_section, chunk_size = chunk_size, chunk_overlap = chunk_overlap))\n",
    "print(f\"{chunks_cd.count()} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST CHUNKING SIZE AND OVERLAP\n",
    "from langchain.document_loaders import ReadTheDocsLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import csv\n",
    "\n",
    "# Define the chunk size and overlap\n",
    "chunk_size = 300\n",
    "chunk_overlap = 20\n",
    "\n",
    "# Open and read the CSV file\n",
    "with open('league_lore.csv', 'r', encoding='utf8') as file:\n",
    "    csv_reader = csv.DictReader(file)\n",
    "    championdata = [row for row in csv_reader]\n",
    "\n",
    "# Call the chunk_section method\n",
    "chunks_result = chunk_section(championdata, chunk_size, chunk_overlap)\n",
    "\n",
    "# Print the resulting chunks\n",
    "for chunk in chunks_result:\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "Embedding"
    ]
   },
   "outputs": [],
   "source": [
    "#EMBEDDING \n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "from ray.data import ActorPoolStrategy\n",
    "\n",
    "class EmbedChunks:\n",
    "    def __init__(self, model_name):\n",
    "        if model_name == \"text-embedding-ada-002\":\n",
    "            self.embedding_model = OpenAIEmbeddings(\n",
    "                model=model_name,\n",
    "                openai_api_base=os.environ[\"OPENAI_API_BASE\"],\n",
    "                openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "        else:\n",
    "            self.embedding_model = HuggingFaceEmbeddings(\n",
    "                model_name=model_name,\n",
    "                model_kwargs={\"device\": \"cuda\"},\n",
    "                encode_kwargs={\"device\": \"cuda\", \"batch_size\": 100})\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        embeddings = self.embedding_model.embed_documents(batch[\"text\"])\n",
    "        return {\"text\": batch[\"text\"], \"source\": batch[\"source\"], \"embeddings\": embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed chunks\n",
    "embedding_model_name = \"thenlper/gte-base\"\n",
    "embedded_chunks = chunks_ds.map_batches(\n",
    "    EmbedChunks,\n",
    "    fn_constructor_kwargs={\"model_name\": embedding_model_name},\n",
    "    batch_size=100, \n",
    "    num_gpus=1,\n",
    "    compute=ActorPoolStrategy(size=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_section(\"league_lore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = collection.query(\n",
    "    query_texts=[\"Which champions are from Shurima\"],\n",
    "    n_results=1,\n",
    "    include=['documents']\n",
    ")\n",
    "\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
